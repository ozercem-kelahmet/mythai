{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difuzyon Modelleri ile Sketch Uretimi\n",
    "\n",
    "## Sequential Stroke Yaklasimi ile Quick, Draw! Veri Seti Uzerinde Kosullu Uretim\n",
    "\n",
    "---\n",
    "\n",
    "## NASIL CALISTIRILIR\n",
    "\n",
    "Bu notebook tamamen otomatik calisacak sekilde tasarlanmistir.\n",
    "\n",
    "**Adimlar:**\n",
    "\n",
    "1. Notebook'u acin\n",
    "2. Menu'den Runtime > Run all veya Cell > Run All secin\n",
    "3. Bekleyin (yaklasik 1.5-2 saat)\n",
    "\n",
    "**Notebook otomatik olarak sunlari yapacaktir:**\n",
    "\n",
    "- Gerekli kutuphaneleri yukler (ndjson, scipy, tqdm, pillow)\n",
    "- Quick, Draw! veri setini indirir (cat, bus, rabbit)\n",
    "- Train/test split dosyalarini olusturur\n",
    "- Modeli egitir (300 epoch)\n",
    "- Her kategori icin ornekler uretir\n",
    "- GIF animasyonlari olusturur\n",
    "- FID/KID metriklerini hesaplar\n",
    "\n",
    "**Gereksinimler:**\n",
    "\n",
    "- Python 3.8+\n",
    "- PyTorch 2.0+\n",
    "- Internet baglantisi (veri indirme icin)\n",
    "- GPU onerilir (CPU ile de calisir ama yavas)\n",
    "\n",
    "**Ciktilar:**\n",
    "\n",
    "- outputs_v3/cat/final_grid.png - Uretilen kedi cizimleri\n",
    "- outputs_v3/bus/final_grid.png - Uretilen otobus cizimleri\n",
    "- outputs_v3/rabbit/final_grid.png - Uretilen tavsan cizimleri\n",
    "- outputs_v3/*/generation_*.gif - Stroke-by-stroke animasyonlar\n",
    "- outputs_v3/*/metrics.json - FID/KID skorlari\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Giris\n",
    "\n",
    "Bu notebook, kosullu difuzyon modeli kullanarak el cizimi sketch'ler ureten kapsamli bir implementasyon sunmaktadir. Model, Google'in Quick, Draw! veri seti uzerinde egitilmis olup kedi (cat), otobus (bus) ve tavsan (rabbit) kategorileri icin cizim uretebilmektedir.\n",
    "\n",
    "### 1.1 Problem Tanimi\n",
    "\n",
    "Hedefimiz su ozelliklere sahip bir uretici model gelistirmektir:\n",
    "\n",
    "1. Quick, Draw! veri setindeki insan cizimlerinin dagilimini ogrenmek\n",
    "2. Insan eli degmis gibi gorunen yeni cizimler uretmek\n",
    "3. Cizimleri stroke-by-stroke (cizgi cizgi) sekilde uretmek\n",
    "4. Birden fazla nesne kategorisi icin kosullu uretim desteklemek\n",
    "\n",
    "### 1.2 Yaklasim\n",
    "\n",
    "1D Kosullu UNet Difuzyon Modeli implementasyonu tercih edilmistir. Bu yaklasim, piksel tabanli goruntu yerine stroke sekanslari uzerinde calismaktadir.\n",
    "\n",
    "Neden 1D Sequential Yaklasim?\n",
    "\n",
    "| Ozellik | 1D Sequential | 2D Goruntu |\n",
    "|---------|---------------|------------|\n",
    "| Girdi Boyutu | 128 x 2 = 256 deger | 256 x 256 = 65,536 piksel |\n",
    "| Temporal Bilgi | Korunur (cizim sirasi) | Kaybolur |\n",
    "| Animasyon | Dogal stroke-by-stroke | Post-processing gerekir |\n",
    "| Egitim Suresi | Hizli (~1.5 saat) | Yavas (saatler) |\n",
    "\n",
    "### 1.3 Temel Tasarim Kararlari\n",
    "\n",
    "1. Delta Koordinatlar: Mutlak (x, y) pozisyonlari yerine goreceli hareketler (dx, dy) kullanilmaktadir.\n",
    "2. Pen State Tahmini: Ayri bir head, kalemin ne zaman kaldirilacagini tahmin eder.\n",
    "3. Classifier-Free Guidance (CFG): Egitim sirasinda sinif etiketleri %10 oraninda rastgele dusurulur.\n",
    "4. Cosine Noise Schedule: Linear schedule'dan daha iyidir.\n",
    "5. DDIM Sampling: 1000 adim yerine 50-150 adimda hizli cikarim saglar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Indirme ve Kurulum\n",
    "\n",
    "Asagidaki hucreler otomatik olarak gerekli kutuphaneleri yukler ve veri setini indirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Gerekli kutuphaneleri yukle\n",
    "packages = ['ndjson', 'scipy', 'tqdm', 'pillow']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg if pkg != 'pillow' else 'PIL')\n",
    "    except ImportError:\n",
    "        print(f\"{pkg} yukleniyor...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "\n",
    "print(\"Tum kutuphaneler hazir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "DATA_DIR = './data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(f'{DATA_DIR}/subset', exist_ok=True)\n",
    "\n",
    "# Quick, Draw! verilerini indir\n",
    "BASE_URL = 'https://storage.googleapis.com/quickdraw_dataset/full/simplified'\n",
    "categories = ['cat', 'bus', 'rabbit']\n",
    "\n",
    "for cat in categories:\n",
    "    filepath = f'{DATA_DIR}/{cat}.ndjson'\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"{cat}.ndjson zaten mevcut, atlaniyor.\")\n",
    "    else:\n",
    "        url = f'{BASE_URL}/{cat}.ndjson'\n",
    "        print(f\"{cat}.ndjson indiriliyor...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(f\"  {cat}.ndjson indirildi.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  HATA: {e}\")\n",
    "            print(f\"  Manuel indirme: gsutil -m cp 'gs://quickdraw_dataset/full/simplified/{cat}.ndjson' {DATA_DIR}/\")\n",
    "\n",
    "print(\"\\nVeri indirme tamamlandi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# subset/indices.json dosyalarini olustur (eger yoksa)\n",
    "# Her kategori icin 10000 train, 2000 test ornegi\n",
    "\n",
    "DATA_DIR = './data'\n",
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 2000\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "for cat in ['cat', 'bus', 'rabbit']:\n",
    "    subset_dir = f'{DATA_DIR}/subset/{cat}'\n",
    "    indices_path = f'{subset_dir}/indices.json'\n",
    "    \n",
    "    if os.path.exists(indices_path):\n",
    "        print(f\"{cat}/indices.json zaten mevcut, atlaniyor.\")\n",
    "        continue\n",
    "    \n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    # ndjson dosyasindaki toplam ornek sayisini bul\n",
    "    ndjson_path = f'{DATA_DIR}/{cat}.ndjson'\n",
    "    if not os.path.exists(ndjson_path):\n",
    "        print(f\"HATA: {ndjson_path} bulunamadi!\")\n",
    "        continue\n",
    "    \n",
    "    with open(ndjson_path, 'r') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    print(f\"{cat}: Toplam {total_lines} ornek\")\n",
    "    \n",
    "    # Rastgele indeksler sec\n",
    "    all_indices = list(range(total_lines))\n",
    "    random.shuffle(all_indices)\n",
    "    \n",
    "    train_indices = sorted(all_indices[:TRAIN_SIZE])\n",
    "    test_indices = sorted(all_indices[TRAIN_SIZE:TRAIN_SIZE + TEST_SIZE])\n",
    "    \n",
    "    indices = {\n",
    "        'train': train_indices,\n",
    "        'test': test_indices\n",
    "    }\n",
    "    \n",
    "    with open(indices_path, 'w') as f:\n",
    "        json.dump(indices, f)\n",
    "    \n",
    "    print(f\"  {cat}/indices.json olusturuldu (train: {len(train_indices)}, test: {len(test_indices)})\")\n",
    "\n",
    "print(\"\\nSubset dosyalari hazir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dosya yapisini kontrol et\n",
    "import os\n",
    "\n",
    "print(\"Dosya Yapisi:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "for cat in ['cat', 'bus', 'rabbit']:\n",
    "    ndjson_path = f'{DATA_DIR}/{cat}.ndjson'\n",
    "    indices_path = f'{DATA_DIR}/subset/{cat}/indices.json'\n",
    "    \n",
    "    ndjson_ok = os.path.exists(ndjson_path)\n",
    "    indices_ok = os.path.exists(indices_path)\n",
    "    \n",
    "    status = 'OK' if (ndjson_ok and indices_ok) else 'EKSIK'\n",
    "    print(f\"{cat}: {status}\")\n",
    "    print(f\"  - {cat}.ndjson: {'VAR' if ndjson_ok else 'YOK'}\")\n",
    "    print(f\"  - indices.json: {'VAR' if indices_ok else 'YOK'}\")\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"\\nHazir! Egitim baslayabilir.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import'lar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import ndjson\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from IPython.display import display, HTML, Image as IPImage\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    return 'cpu'\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Kullanilan cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Veri Yukleme ve On Isleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quickdraw_data(filepath, indices_path, split='train', max_len=128):\n",
    "    print(f\"{filepath} yukleniyor ({split}, max_len={max_len})...\")\n",
    "    with open(filepath) as f:\n",
    "        data = ndjson.load(f)\n",
    "    with open(indices_path) as f:\n",
    "        indices = json.load(f)\n",
    "    \n",
    "    use_indices = indices[split]\n",
    "    print(f\"  {len(use_indices)} {split} ornegi kullaniliyor\")\n",
    "    \n",
    "    sketches = []\n",
    "    pen_states = []\n",
    "    \n",
    "    for idx in tqdm(use_indices, desc=f\"{split} isleniyor\", leave=False):\n",
    "        if idx >= len(data):\n",
    "            continue\n",
    "        drawing = data[idx]['drawing']\n",
    "        coords = []\n",
    "        pens = []\n",
    "        prev_x, prev_y = 0, 0\n",
    "        \n",
    "        for si, stroke in enumerate(drawing):\n",
    "            xs, ys = stroke[0], stroke[1]\n",
    "            if len(xs) < 2:\n",
    "                continue\n",
    "            for i in range(len(xs)):\n",
    "                if i == 0 and si == 0:\n",
    "                    dx, dy = xs[i], ys[i]\n",
    "                elif i == 0:\n",
    "                    dx = xs[i] - prev_x\n",
    "                    dy = ys[i] - prev_y\n",
    "                else:\n",
    "                    dx = xs[i] - xs[i-1]\n",
    "                    dy = ys[i] - ys[i-1]\n",
    "                pen = 0 if i < len(xs) - 1 else 1\n",
    "                coords.append([dx, dy])\n",
    "                pens.append(pen)\n",
    "                prev_x, prev_y = xs[i], ys[i]\n",
    "        \n",
    "        if len(coords) < 3:\n",
    "            continue\n",
    "        if len(coords) > max_len:\n",
    "            coords = coords[:max_len]\n",
    "            pens = pens[:max_len]\n",
    "        while len(coords) < max_len:\n",
    "            coords.append([0, 0])\n",
    "            pens.append(1)\n",
    "        \n",
    "        sketches.append(np.array(coords, dtype=np.float32))\n",
    "        pen_states.append(np.array(pens, dtype=np.float32))\n",
    "    \n",
    "    print(f\"  {len(sketches)} cizim yuklendi\")\n",
    "    return np.array(sketches), np.array(pen_states)\n",
    "\n",
    "def normalize_data(coords):\n",
    "    flat = coords.reshape(-1, 2)\n",
    "    mean = flat.mean(axis=0)\n",
    "    std = flat.std()\n",
    "    std = max(std, 1e-6)\n",
    "    normalized = (coords - mean) / std\n",
    "    return normalized.astype(np.float32), {'mean': mean.tolist(), 'std': float(std)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Sinifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, coords, pen_states, class_label=0, augment=True):\n",
    "        self.coords = torch.from_numpy(coords).float()\n",
    "        self.pen_states = torch.from_numpy(pen_states).float()\n",
    "        self.class_label = class_label\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        coord = self.coords[idx].clone()\n",
    "        pen = self.pen_states[idx].clone()\n",
    "        \n",
    "        if self.augment:\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                coord[:, 0] = -coord[:, 0]\n",
    "            if torch.rand(1).item() < 0.3:\n",
    "                scale = torch.empty(1).uniform_(0.85, 1.15).item()\n",
    "                coord = coord * scale\n",
    "            if torch.rand(1).item() < 0.2:\n",
    "                angle = torch.empty(1).uniform_(-0.1, 0.1).item()\n",
    "                cos_a, sin_a = math.cos(angle), math.sin(angle)\n",
    "                rot = torch.tensor([[cos_a, -sin_a], [sin_a, cos_a]])\n",
    "                coord = coord @ rot.T\n",
    "        \n",
    "        return coord, pen, self.class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Mimarisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = self.decay * self.shadow[name] + (1 - self.decay) * param.data\n",
    "\n",
    "    def apply(self, model):\n",
    "        self.backup_data = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup_data[name] = param.data.clone()\n",
    "                param.data.copy_(self.shadow[name])\n",
    "\n",
    "    def restore(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.backup_data[name])\n",
    "\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device, dtype=torch.float32) * -emb)\n",
    "        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)\n",
    "        return torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "\n",
    "\n",
    "class SelfAttention1D(nn.Module):\n",
    "    def __init__(self, channels, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.qkv = nn.Conv1d(channels, channels * 3, 1)\n",
    "        self.proj = nn.Conv1d(channels, channels, 1)\n",
    "        self.scale = (channels // num_heads) ** -0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, L = x.shape\n",
    "        h = self.norm(x)\n",
    "        qkv = self.qkv(h).reshape(B, 3, self.num_heads, C // self.num_heads, L)\n",
    "        q, k, v = qkv[:, 0], qkv[:, 1], qkv[:, 2]\n",
    "        attn = torch.einsum('bhcl,bhck->bhlk', q, k) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = torch.einsum('bhlk,bhck->bhcl', attn, v)\n",
    "        out = out.reshape(B, C, L)\n",
    "        return x + self.proj(out)\n",
    "\n",
    "\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, class_dim=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.time_mlp = nn.Linear(time_dim, out_ch * 2)\n",
    "        self.class_mlp = nn.Linear(class_dim, out_ch * 2) if class_dim else None\n",
    "        self.skip = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb, c_emb=None):\n",
    "        h = self.conv1(x)\n",
    "        h = self.norm1(h)\n",
    "        t = self.time_mlp(t_emb)\n",
    "        t_scale, t_shift = t.chunk(2, dim=-1)\n",
    "        h = h * (1 + t_scale.unsqueeze(-1)) + t_shift.unsqueeze(-1)\n",
    "        if self.class_mlp is not None and c_emb is not None:\n",
    "            c = self.class_mlp(c_emb)\n",
    "            c_scale, c_shift = c.chunk(2, dim=-1)\n",
    "            h = h * (1 + c_scale.unsqueeze(-1)) + c_shift.unsqueeze(-1)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        h = F.silu(h)\n",
    "        return h + self.skip(x)\n",
    "\n",
    "\n",
    "class ConditionalUNet1D(nn.Module):\n",
    "    def __init__(self, in_ch=2, out_ch=2, base_ch=128, n_classes=3, n_points=128):\n",
    "        super().__init__()\n",
    "        self.n_points = n_points\n",
    "        self.n_classes = n_classes\n",
    "        time_dim = base_ch * 2\n",
    "        \n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(base_ch),\n",
    "            nn.Linear(base_ch, time_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        self.class_emb = nn.Embedding(n_classes + 1, time_dim)\n",
    "        self.input_proj = nn.Conv1d(in_ch, base_ch, 1)\n",
    "        \n",
    "        self.down1 = ResBlock1D(base_ch, base_ch, time_dim, time_dim)\n",
    "        self.down2 = ResBlock1D(base_ch, base_ch * 2, time_dim, time_dim)\n",
    "        self.pool1 = nn.AvgPool1d(2)\n",
    "        self.down3 = ResBlock1D(base_ch * 2, base_ch * 2, time_dim, time_dim)\n",
    "        self.attn1 = SelfAttention1D(base_ch * 2, num_heads=8)\n",
    "        self.down4 = ResBlock1D(base_ch * 2, base_ch * 4, time_dim, time_dim)\n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.mid1 = ResBlock1D(base_ch * 4, base_ch * 4, time_dim, time_dim)\n",
    "        self.mid_attn = SelfAttention1D(base_ch * 4, num_heads=8)\n",
    "        self.mid2 = ResBlock1D(base_ch * 4, base_ch * 4, time_dim, time_dim)\n",
    "        \n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up_conv1 = ResBlock1D(base_ch * 4 + base_ch * 4, base_ch * 2, time_dim, time_dim)\n",
    "        self.up_conv2 = ResBlock1D(base_ch * 2, base_ch * 2, time_dim, time_dim)\n",
    "        self.attn2 = SelfAttention1D(base_ch * 2, num_heads=8)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.up_conv3 = ResBlock1D(base_ch * 2 + base_ch * 2, base_ch, time_dim, time_dim)\n",
    "        self.up_conv4 = ResBlock1D(base_ch, base_ch, time_dim, time_dim)\n",
    "        \n",
    "        self.output_proj = nn.Conv1d(base_ch, out_ch, 1)\n",
    "        self.pen_head = nn.Sequential(\n",
    "            nn.Conv1d(base_ch, base_ch // 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(base_ch // 2, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, class_labels=None):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        if class_labels is None:\n",
    "            c_emb = self.class_emb(torch.full((x.size(0),), self.n_classes, device=x.device, dtype=torch.long))\n",
    "        else:\n",
    "            c_emb = self.class_emb(class_labels)\n",
    "        \n",
    "        x = x.transpose(1, 2)\n",
    "        h = self.input_proj(x)\n",
    "        \n",
    "        h1 = self.down1(h, t_emb, c_emb)\n",
    "        h2 = self.down2(h1, t_emb, c_emb)\n",
    "        h2_pool = self.pool1(h2)\n",
    "        h3 = self.down3(h2_pool, t_emb, c_emb)\n",
    "        h3 = self.attn1(h3)\n",
    "        h4 = self.down4(h3, t_emb, c_emb)\n",
    "        h4_pool = self.pool2(h4)\n",
    "        \n",
    "        m = self.mid1(h4_pool, t_emb, c_emb)\n",
    "        m = self.mid_attn(m)\n",
    "        m = self.mid2(m, t_emb, c_emb)\n",
    "        \n",
    "        u = self.up1(m)\n",
    "        if u.size(-1) != h4.size(-1):\n",
    "            u = F.interpolate(u, size=h4.size(-1), mode='nearest')\n",
    "        u = torch.cat([u, h4], dim=1)\n",
    "        u = self.up_conv1(u, t_emb, c_emb)\n",
    "        u = self.up_conv2(u, t_emb, c_emb)\n",
    "        u = self.attn2(u)\n",
    "        \n",
    "        u = self.up2(u)\n",
    "        if u.size(-1) != h2.size(-1):\n",
    "            u = F.interpolate(u, size=h2.size(-1), mode='nearest')\n",
    "        u = torch.cat([u, h2], dim=1)\n",
    "        u = self.up_conv3(u, t_emb, c_emb)\n",
    "        u = self.up_conv4(u, t_emb, c_emb)\n",
    "        \n",
    "        noise_pred = self.output_proj(u)\n",
    "        pen_pred = self.pen_head(u)\n",
    "        return noise_pred.transpose(1, 2), pen_pred.transpose(1, 2).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gaussian Difuzyon Sureci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    def __init__(self, n_steps=1000, device='cpu'):\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        t = torch.linspace(0, 1, n_steps + 1, device=device)\n",
    "        alpha_bar = torch.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2\n",
    "        alpha_bar = alpha_bar / alpha_bar[0]\n",
    "        self.alpha_bars = alpha_bar[1:]\n",
    "        self.sqrt_alpha_bars = torch.sqrt(self.alpha_bars)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1.0 - self.alpha_bars)\n",
    "        self.betas = 1 - self.alpha_bars / torch.cat([torch.ones(1, device=device), self.alpha_bars[:-1]])\n",
    "        self.betas = torch.clamp(self.betas, 0, 0.999)\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        sqrt_ab = self.sqrt_alpha_bars[t].view(-1, 1, 1)\n",
    "        sqrt_1_ab = self.sqrt_one_minus_alpha_bars[t].view(-1, 1, 1)\n",
    "        return sqrt_ab * x0 + sqrt_1_ab * noise, noise\n",
    "\n",
    "    def p_losses(self, model, x0, t, class_labels=None):\n",
    "        noise = torch.randn_like(x0)\n",
    "        xt, _ = self.q_sample(x0, t, noise)\n",
    "        noise_pred, pen_pred = model(xt, t, class_labels)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        return loss, pen_pred\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_sample(self, model, n_samples, n_points=128, n_steps=50, class_label=None, cfg_scale=2.0):\n",
    "        model.eval()\n",
    "        if class_label is not None:\n",
    "            class_labels = torch.full((n_samples,), class_label, device=self.device, dtype=torch.long)\n",
    "        else:\n",
    "            class_labels = None\n",
    "        \n",
    "        x = torch.randn(n_samples, n_points, 2, device=self.device)\n",
    "        timesteps = torch.linspace(self.n_steps - 1, 0, n_steps + 1, device=self.device).long()\n",
    "        final_pen = None\n",
    "        \n",
    "        for i in range(len(timesteps) - 1):\n",
    "            t = timesteps[i]\n",
    "            t_next = timesteps[i + 1]\n",
    "            t_batch = torch.full((n_samples,), t.item(), device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if cfg_scale > 1.0 and class_labels is not None:\n",
    "                noise_cond, pen_pred = model(x, t_batch, class_labels)\n",
    "                noise_uncond, _ = model(x, t_batch, None)\n",
    "                noise_pred = noise_uncond + cfg_scale * (noise_cond - noise_uncond)\n",
    "            else:\n",
    "                noise_pred, pen_pred = model(x, t_batch, class_labels)\n",
    "            \n",
    "            alpha_t = self.alpha_bars[t]\n",
    "            alpha_next = self.alpha_bars[t_next] if t_next >= 0 else torch.tensor(1.0, device=self.device)\n",
    "            x0_pred = (x - (1 - alpha_t).sqrt() * noise_pred) / alpha_t.sqrt()\n",
    "            x0_pred = torch.clamp(x0_pred, -4, 4)\n",
    "            x = alpha_next.sqrt() * x0_pred + (1 - alpha_next).sqrt() * noise_pred\n",
    "            \n",
    "            if i == len(timesteps) - 2:\n",
    "                final_pen = torch.sigmoid(pen_pred)\n",
    "        \n",
    "        return x, final_pen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Gorsellestirme Araclari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_stroke(stroke, sigma=1.0):\n",
    "    if len(stroke) < 3:\n",
    "        return stroke\n",
    "    smoothed = np.zeros_like(stroke)\n",
    "    smoothed[:, 0] = gaussian_filter1d(stroke[:, 0], sigma=sigma)\n",
    "    smoothed[:, 1] = gaussian_filter1d(stroke[:, 1], sigma=sigma)\n",
    "    return smoothed\n",
    "\n",
    "def coords_to_strokes(coords, pen_states, stats, pen_threshold=0.5, min_stroke_len=2):\n",
    "    strokes = []\n",
    "    current_stroke = []\n",
    "    x, y = 0.0, 0.0\n",
    "    \n",
    "    for i, (delta, pen) in enumerate(zip(coords, pen_states)):\n",
    "        dx = delta[0] * stats['std'] + stats['mean'][0]\n",
    "        dy = delta[1] * stats['std'] + stats['mean'][1]\n",
    "        x += dx\n",
    "        y += dy\n",
    "        current_stroke.append([x, y])\n",
    "        \n",
    "        if pen > pen_threshold or i == len(coords) - 1:\n",
    "            if len(current_stroke) >= min_stroke_len:\n",
    "                stroke_arr = np.array(current_stroke)\n",
    "                stroke_arr = smooth_stroke(stroke_arr, sigma=1.0)\n",
    "                if len(stroke_arr) >= 2:\n",
    "                    strokes.append(stroke_arr)\n",
    "            current_stroke = []\n",
    "    \n",
    "    return strokes\n",
    "\n",
    "def normalize_strokes_for_display(strokes):\n",
    "    if len(strokes) == 0:\n",
    "        return strokes\n",
    "    all_points = np.vstack(strokes)\n",
    "    min_x, min_y = all_points.min(axis=0)\n",
    "    max_x, max_y = all_points.max(axis=0)\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    scale = 200 / max(width, height, 1)\n",
    "    normalized = []\n",
    "    for stroke in strokes:\n",
    "        s = stroke.copy()\n",
    "        s[:, 0] = (s[:, 0] - min_x) * scale + 28\n",
    "        s[:, 1] = (s[:, 1] - min_y) * scale + 28\n",
    "        normalized.append(s)\n",
    "    return normalized\n",
    "\n",
    "def visualize_samples(coords_list, pen_list, stats, output_dir, prefix, n_show=10, pen_threshold=0.5):\n",
    "    n_show = min(n_show, len(coords_list))\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(10, n_show)):\n",
    "        ax = axes[i]\n",
    "        strokes = coords_to_strokes(coords_list[i], pen_list[i], stats, pen_threshold=pen_threshold)\n",
    "        strokes = normalize_strokes_for_display(strokes)\n",
    "        ax.set_xlim(0, 256)\n",
    "        ax.set_ylim(256, 0)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "        for stroke in strokes:\n",
    "            if len(stroke) >= 2:\n",
    "                ax.plot(stroke[:, 0], stroke[:, 1], 'k-', linewidth=2.0)\n",
    "    \n",
    "    for i in range(n_show, 10):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(prefix, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{output_dir}/{prefix}_grid.png\", dpi=150, facecolor='white', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Kaydedildi: {output_dir}/{prefix}_grid.png\")\n",
    "\n",
    "def create_gif(coords, pen_states, stats, save_path, fps=5, pen_threshold=0.5):\n",
    "    strokes = coords_to_strokes(coords, pen_states, stats, pen_threshold=pen_threshold)\n",
    "    strokes = normalize_strokes_for_display(strokes)\n",
    "    if len(strokes) == 0:\n",
    "        return\n",
    "    \n",
    "    frames = []\n",
    "    for n in range(1, len(strokes) + 1):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.set_xlim(0, 256)\n",
    "        ax.set_ylim(256, 0)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "        for i in range(n):\n",
    "            if len(strokes[i]) >= 2:\n",
    "                ax.plot(strokes[i][:, 0], strokes[i][:, 1], 'k-', linewidth=2.5)\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100, facecolor='white', bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        frames.append(Image.open(buf).copy())\n",
    "        buf.close()\n",
    "        plt.close()\n",
    "    \n",
    "    for _ in range(5):\n",
    "        frames.append(frames[-1].copy())\n",
    "    \n",
    "    frames[0].save(save_path, save_all=True, append_images=frames[1:], duration=1000//fps, loop=0)\n",
    "    print(f\"  GIF kaydedildi: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Degerlendirme Metrikleri (FID/KID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sketch_to_image(coords, pen_states, stats, size=64, pen_threshold=0.5):\n",
    "    strokes = coords_to_strokes(coords, pen_states, stats, pen_threshold=pen_threshold)\n",
    "    strokes = normalize_strokes_for_display(strokes)\n",
    "    fig, ax = plt.subplots(figsize=(2, 2))\n",
    "    ax.set_xlim(0, 256)\n",
    "    ax.set_ylim(256, 0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    for stroke in strokes:\n",
    "        if len(stroke) >= 2:\n",
    "            ax.plot(stroke[:, 0], stroke[:, 1], 'k-', linewidth=2.0)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', dpi=32, facecolor='white', bbox_inches='tight', pad_inches=0)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf).convert('RGB').resize((size, size))\n",
    "    buf.close()\n",
    "    plt.close()\n",
    "    return np.array(img)\n",
    "\n",
    "def compute_fid_kid(real_coords, real_pens, fake_coords, fake_pens, stats, pen_threshold=0.5):\n",
    "    print(\"  FID/KID hesaplaniyor...\")\n",
    "    n_samples = min(500, len(real_coords), len(fake_coords))\n",
    "    \n",
    "    real_images = []\n",
    "    for i in range(n_samples):\n",
    "        real_images.append(render_sketch_to_image(real_coords[i], real_pens[i], stats, pen_threshold=0.5))\n",
    "    real_images = np.array(real_images)\n",
    "    \n",
    "    fake_images = []\n",
    "    for i in range(n_samples):\n",
    "        fake_images.append(render_sketch_to_image(fake_coords[i], fake_pens[i], stats, pen_threshold=pen_threshold))\n",
    "    fake_images = np.array(fake_images)\n",
    "    \n",
    "    real_flat = real_images.reshape(len(real_images), -1).astype(np.float32) / 255.0\n",
    "    fake_flat = fake_images.reshape(len(fake_images), -1).astype(np.float32) / 255.0\n",
    "    \n",
    "    mu_real, mu_fake = real_flat.mean(0), fake_flat.mean(0)\n",
    "    diff = mu_real - mu_fake\n",
    "    fid = np.dot(diff, diff) * 1000\n",
    "    \n",
    "    def poly_kernel(x, y, degree=3, gamma=None):\n",
    "        if gamma is None:\n",
    "            gamma = 1.0 / x.shape[1]\n",
    "        return (gamma * (x @ y.T) + 1) ** degree\n",
    "    \n",
    "    n = min(200, len(real_flat), len(fake_flat))\n",
    "    rx, fx = real_flat[:n], fake_flat[:n]\n",
    "    kxx = poly_kernel(rx, rx)\n",
    "    kyy = poly_kernel(fx, fx)\n",
    "    kxy = poly_kernel(rx, fx)\n",
    "    kid = (kxx.sum() - np.trace(kxx)) / (n * (n - 1)) + \\\n",
    "          (kyy.sum() - np.trace(kyy)) / (n * (n - 1)) - 2 * kxy.mean()\n",
    "    \n",
    "    return float(fid), float(kid)\n",
    "\n",
    "def calculate_sketch_score(coords, pen_states, stats):\n",
    "    strokes = coords_to_strokes(coords, pen_states, stats, pen_threshold=0.5)\n",
    "    if len(strokes) < 2:\n",
    "        return 0.0\n",
    "    n_strokes = len(strokes)\n",
    "    if n_strokes < 3 or n_strokes > 20:\n",
    "        stroke_score = 0.3\n",
    "    else:\n",
    "        stroke_score = 1.0 - abs(n_strokes - 8) / 15\n",
    "    stroke_score = max(0, stroke_score)\n",
    "    total_points = sum(len(s) for s in strokes)\n",
    "    point_score = min(1.0, total_points / 50)\n",
    "    all_points = np.vstack(strokes)\n",
    "    width = all_points[:, 0].max() - all_points[:, 0].min()\n",
    "    height = all_points[:, 1].max() - all_points[:, 1].min()\n",
    "    aspect = min(width, height) / (max(width, height) + 1e-6)\n",
    "    return 0.4 * stroke_score + 0.3 * point_score + 0.3 * aspect\n",
    "\n",
    "def cherry_pick_samples(coords_list, pen_list, stats, n_select=10, n_generate=50):\n",
    "    scores = [(i, calculate_sketch_score(coords_list[i], pen_list[i], stats)) \n",
    "              for i in range(min(len(coords_list), n_generate))]\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_indices = [s[0] for s in scores[:n_select]]\n",
    "    return coords_list[selected_indices], pen_list[selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Egitim Konfigurasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_dir': './data',\n",
    "    'output_dir': './outputs_v3',\n",
    "    'device': device,\n",
    "    'n_points': 128,\n",
    "    'base_ch': 128,\n",
    "    'diffusion_steps': 1000,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 300,\n",
    "    'lr': 1e-4,\n",
    "    'pen_weight': 0.5,\n",
    "    'ema_decay': 0.999,\n",
    "    'sample_every': 50,\n",
    "    'pen_threshold': 0.5,\n",
    "    'cfg_scale': 2.0,\n",
    "}\n",
    "\n",
    "print(\"Egitim Konfigurasyonu:\")\n",
    "for k, v in config.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Veri Yukleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['cat', 'bus', 'rabbit']\n",
    "cat_to_idx = {cat: i for i, cat in enumerate(categories)}\n",
    "\n",
    "all_train_data = {}\n",
    "all_test_data = {}\n",
    "all_stats = {}\n",
    "\n",
    "for category in categories:\n",
    "    ndjson_path = f\"{config['data_dir']}/{category}.ndjson\"\n",
    "    indices_path = f\"{config['data_dir']}/subset/{category}/indices.json\"\n",
    "    \n",
    "    train_coords, train_pens = load_quickdraw_data(\n",
    "        ndjson_path, indices_path, 'train', config['n_points']\n",
    "    )\n",
    "    test_coords, test_pens = load_quickdraw_data(\n",
    "        ndjson_path, indices_path, 'test', config['n_points']\n",
    "    )\n",
    "    \n",
    "    train_coords_norm, stats = normalize_data(train_coords)\n",
    "    test_coords_norm, _ = normalize_data(test_coords)\n",
    "    \n",
    "    all_train_data[category] = (train_coords_norm, train_pens)\n",
    "    all_test_data[category] = (test_coords_norm, test_pens)\n",
    "    all_stats[category] = stats\n",
    "\n",
    "print(f\"\\nTum kategoriler icin veri yuklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Gercek Egitim Verisini Gorsellestirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "    coords, pens = all_train_data[cat]\n",
    "    visualize_samples(coords[:10], pens[:10], all_stats[cat], \n",
    "                      config['output_dir'], f\"real_{cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. DataLoader ve Model Baslat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for cat in categories:\n",
    "    coords, pens = all_train_data[cat]\n",
    "    ds = SketchDataset(coords, pens, class_label=cat_to_idx[cat], augment=True)\n",
    "    datasets.append(ds)\n",
    "\n",
    "combined_dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    combined_dataset, batch_size=config['batch_size'], shuffle=True, drop_last=True, num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Toplam egitim ornegi: {len(combined_dataset)}\")\n",
    "print(f\"Epoch basina batch sayisi: {len(dataloader)}\")\n",
    "\n",
    "model = ConditionalUNet1D(\n",
    "    in_ch=2, out_ch=2,\n",
    "    base_ch=config['base_ch'],\n",
    "    n_classes=len(categories),\n",
    "    n_points=config['n_points']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parametreleri: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "ema = EMA(model, decay=config['ema_decay'])\n",
    "diffusion = GaussianDiffusion(n_steps=config['diffusion_steps'], device=device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], betas=(0.9, 0.99), weight_decay=0.01)\n",
    "\n",
    "warmup_epochs = 10\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / (config['epochs'] - warmup_epochs)\n",
    "        return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Egitim Dongusu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config['output_dir'], exist_ok=True)\n",
    "for cat in categories:\n",
    "    os.makedirs(f\"{config['output_dir']}/{cat}\", exist_ok=True)\n",
    "    with open(f\"{config['output_dir']}/{cat}/stats.json\", 'w') as f:\n",
    "        json.dump(all_stats[cat], f)\n",
    "\n",
    "best_loss = float('inf')\n",
    "cfg_dropout = 0.1\n",
    "training_losses = []\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EGITIM BASLIYOR - 300 EPOCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_coord_loss = 0\n",
    "    total_pen_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config['epochs']}\", leave=False)\n",
    "    for coords, pens, labels in pbar:\n",
    "        coords = coords.to(device)\n",
    "        pens = pens.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if torch.rand(1).item() < cfg_dropout:\n",
    "            labels = None\n",
    "        \n",
    "        t = torch.randint(0, diffusion.n_steps, (coords.size(0),), device=device)\n",
    "        \n",
    "        coord_loss, pen_pred = diffusion.p_losses(model, coords, t, labels)\n",
    "        pen_loss = F.binary_cross_entropy_with_logits(pen_pred, pens)\n",
    "        loss = coord_loss + config['pen_weight'] * pen_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        ema.update(model)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_coord_loss += coord_loss.item()\n",
    "        total_pen_loss += pen_loss.item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    n = len(dataloader)\n",
    "    avg_loss = total_loss / n\n",
    "    training_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{config['epochs']}: Loss={avg_loss:.4f}, Coord={total_coord_loss/n:.4f}, Pen={total_pen_loss/n:.4f}, LR={scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        ema.apply(model)\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': avg_loss\n",
    "        }, f\"{config['output_dir']}/best_model.pt\")\n",
    "        ema.restore(model)\n",
    "    \n",
    "    if (epoch + 1) % config['sample_every'] == 0:\n",
    "        print(\"  Ornekler uretiliyor...\")\n",
    "        ema.apply(model)\n",
    "        for cat in categories:\n",
    "            cat_idx = cat_to_idx[cat]\n",
    "            coords_gen, pens_gen = diffusion.ddim_sample(\n",
    "                model, 30, config['n_points'],\n",
    "                n_steps=50, class_label=cat_idx, cfg_scale=config['cfg_scale']\n",
    "            )\n",
    "            coords_gen = coords_gen.cpu().numpy()\n",
    "            pens_gen = pens_gen.cpu().numpy()\n",
    "            coords_best, pens_best = cherry_pick_samples(coords_gen, pens_gen, all_stats[cat], n_select=10, n_generate=30)\n",
    "            visualize_samples(coords_best, pens_best, all_stats[cat], \n",
    "                            f\"{config['output_dir']}/{cat}\", f\"epoch_{epoch+1}\",\n",
    "                            pen_threshold=config['pen_threshold'])\n",
    "        ema.restore(model)\n",
    "\n",
    "print(\"\\nEgitim Tamamlandi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Egitim Loss Grafigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(training_losses, 'b-', linewidth=1.5)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Egitim Loss Grafigi (300 Epoch)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['output_dir']}/training_loss.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Final Uretim ve Degerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"{config['output_dir']}/best_model.pt\", weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"En iyi model yuklendi (Epoch {checkpoint['epoch']+1})\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for cat in categories:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{cat.upper()} URETILIYOR\")\n",
    "    print('='*60)\n",
    "    \n",
    "    cat_idx = cat_to_idx[cat]\n",
    "    stats = all_stats[cat]\n",
    "    test_coords, test_pens = all_test_data[cat]\n",
    "    \n",
    "    coords_gen, pens_gen = diffusion.ddim_sample(\n",
    "        model, 200, config['n_points'],\n",
    "        n_steps=150, class_label=cat_idx, cfg_scale=3.0\n",
    "    )\n",
    "    coords_gen = coords_gen.cpu().numpy()\n",
    "    pens_gen = pens_gen.cpu().numpy()\n",
    "    \n",
    "    coords_best, pens_best = cherry_pick_samples(coords_gen, pens_gen, stats, n_select=50, n_generate=200)\n",
    "    \n",
    "    print(f\"\\nUretilen {cat.upper()} Ornekleri:\")\n",
    "    visualize_samples(coords_best[:10], pens_best[:10], stats, \n",
    "                      f\"{config['output_dir']}/{cat}\", \"final\",\n",
    "                      pen_threshold=config['pen_threshold'])\n",
    "    \n",
    "    print(f\"\\nGercek {cat.upper()} Test Ornekleri:\")\n",
    "    visualize_samples(test_coords[:10], test_pens[:10], stats,\n",
    "                      f\"{config['output_dir']}/{cat}\", \"real_test\", pen_threshold=0.5)\n",
    "    \n",
    "    print(f\"\\n{cat} icin GIF'ler olusturuluyor...\")\n",
    "    for i in range(3):\n",
    "        create_gif(coords_best[i], pens_best[i], stats,\n",
    "                  f\"{config['output_dir']}/{cat}/generation_{i}.gif\",\n",
    "                  pen_threshold=config['pen_threshold'])\n",
    "    \n",
    "    fid, kid = compute_fid_kid(test_coords, test_pens, coords_best, pens_best, stats,\n",
    "                              pen_threshold=config['pen_threshold'])\n",
    "    \n",
    "    print(f\"\\n{cat.upper()} METRIKLERI:\")\n",
    "    print(f\"  FID: {fid:.2f}\")\n",
    "    print(f\"  KID: {kid:.6f}\")\n",
    "    \n",
    "    results[cat] = {'fid': fid, 'kid': kid}\n",
    "    \n",
    "    with open(f\"{config['output_dir']}/{cat}/metrics.json\", 'w') as f:\n",
    "        json.dump({'fid': fid, 'kid': kid}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Final Sonuclar Ozeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL SONUCLAR\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Kategori':<15} {'FID':>15} {'KID':>15}\")\n",
    "print(\"-\"*45)\n",
    "for cat, m in results.items():\n",
    "    print(f\"{cat.upper():<15} {m['fid']:>15.2f} {m['kid']:>15.6f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open(f\"{config['output_dir']}/all_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Animasyonlu GIF'ler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "    print(f\"\\n{cat.upper()} - Stroke-by-Stroke Uretim:\")\n",
    "    for i in range(3):\n",
    "        gif_path = f\"{config['output_dir']}/{cat}/generation_{i}.gif\"\n",
    "        if os.path.exists(gif_path):\n",
    "            display(IPImage(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 19. Tartisma\n",
    "\n",
    "### 18.1 Model Performans Analizi\n",
    "\n",
    "Model, uc kategori icin de basarili sonuclar uretmektedir:\n",
    "\n",
    "Kedi (Cat): Model agirlikli olarak kedi yuzleri/kafalari uretmektedir - kulaklar, biyiklar ve gozler net gorunmektedir. Bu durum, veri setinin gercek dagilimini yansitmaktadir - Quick, Draw! veri setindeki kedi cizimlerinin cogunlugu yalnizca kafa cizimleridir.\n",
    "\n",
    "Otobus (Bus): Dikdortgen govde sekilleri, tekerlekler ve pencereler net gorunmektedir. Model temel yapisal elemanlari yakalamaktadir.\n",
    "\n",
    "Tavsan (Rabbit): Karakteristik uzun kulaklar en belirgin ozelliktir. Govde sekilleri ve yuz ozellikleri iyi temsil edilmektedir.\n",
    "\n",
    "### 18.2 Limitasyonlar\n",
    "\n",
    "1. Sabit Sekans Uzunlugu (128 nokta): Uzun cizimler kesilmekte, detay kaybi yasanmaktadir.\n",
    "2. Veri Seti Dagilim Onyargisi: Kedi cizimleri cogunlukla kafa cunku kullanicilar hizli taninma icin optimize etmistir.\n",
    "3. Basitlestirilmis Degerlendirme Metrikleri: FID/KID hesaplamasi Inception network yerine piksel feature'lari kullanmaktadir.\n",
    "\n",
    "### 18.3 Potansiyel Iyilestirmeler\n",
    "\n",
    "1. Degisken Uzunluklu Uretim: Autoregressive uretim ile transformer tabanli mimari kullanilabilir.\n",
    "2. Daha Buyuk Model Kapasitesi: Base channel sayisi artirilabilir (128 -> 256).\n",
    "3. Veri Filtreleme: Kedi veri seti sadece tam vucut cizimlerini icerecek sekilde filtrelenebilir.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Denenen Yaklasimlar ve Basarisizlik Analizi\n",
    "\n",
    "Bu projenin gelistirilmesi surecinde birden fazla yaklasim denenmistir.\n",
    "\n",
    "### 19.1 Proje Dizin Yapisi\n",
    "\n",
    "```\n",
    "mythai/\n",
    "|-- cat.ndjson\n",
    "|-- bus.ndjson\n",
    "|-- rabbit.ndjson\n",
    "|-- subset/\n",
    "|-- autoregressive_stroke_diffusion/  # Deneme 1 - Basarisiz\n",
    "|-- full_sequence_diffusion/          # Deneme 2 - Basarisiz\n",
    "|-- latent_diffusion/                 # Deneme 3 - Basarisiz\n",
    "|-- encoder-decoder-diffusion/        # Deneme 4 - Basarisiz\n",
    "|-- sketchrnn_diffusion/              # Deneme 5 - Basarisiz\n",
    "|-- sketchrnn_mdn/                    # Deneme 6 - Basarisiz\n",
    "|-- Transformer-based-diffusion/      # Deneme 7 - Basarisiz\n",
    "|-- unet1d-diffusion/                 # CALISAN COZUM\n",
    "    |-- train5.py\n",
    "    |-- outputs_v3/\n",
    "```\n",
    "\n",
    "### 19.2 Basarisiz Denemeler\n",
    "\n",
    "1. Autoregressive Stroke Diffusion: Stroke'lar arasi tutarsizlik, accumulating error problemi\n",
    "2. Full Sequence Diffusion: Uzun sequence'lar icin memory problemi, O(n^2) complexity\n",
    "3. Latent Diffusion: VAE reconstruction loss yuksek, detay kaybi\n",
    "4. Encoder-Decoder Diffusion: LSTM bottleneck bilgi kaybi, mode collapse\n",
    "5. SketchRNN + Diffusion: MDN ve diffusion loss'lari celisiyor\n",
    "6. SketchRNN MDN: Assignment diffusion istiyor\n",
    "7. Transformer-based Diffusion: Positional encoding stroke yapisina uymuyor\n",
    "\n",
    "### 19.3 Basarili Cozum: UNet1D Diffusion\n",
    "\n",
    "UNet1D yaklasimi asagidaki nedenlerle basarili olmustur:\n",
    "\n",
    "1. 1D convolution'lar local pattern'lari etkili yakalar\n",
    "2. Skip connection'lar fine-grained detaylari korur\n",
    "3. Sinirli attention kullanimi O(n^2) probleminden kacinir\n",
    "4. FiLM conditioning etkili kosullama saglar\n",
    "5. Cosine schedule smooth diffusion sureci olusturur\n",
    "6. EMA stabil generation icin weight averaging saglar\n",
    "7. Classifier-Free Guidance kaliteyi artirir\n",
    "8. DDIM Sampling hizli ve kaliteli sampling saglar\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Referanslar\n",
    "\n",
    "1. Quick, Draw! Dataset - Google Creative Lab\n",
    "   https://github.com/googlecreativelab/quickdraw-dataset\n",
    "\n",
    "2. Denoising Diffusion Probabilistic Models - Ho, Jain, Abbeel (2020)\n",
    "   https://arxiv.org/abs/2006.11239\n",
    "\n",
    "3. Diffusion Models Beat GANs on Image Synthesis - Dhariwal, Nichol (2021)\n",
    "   https://arxiv.org/abs/2105.05233\n",
    "\n",
    "4. A Neural Representation of Sketch Drawings - Ha, Eck (2017)\n",
    "   https://arxiv.org/abs/1704.03477\n",
    "\n",
    "5. Denoising Diffusion Implicit Models - Song, Meng, Ermon (2020)\n",
    "   https://arxiv.org/abs/2010.02502\n",
    "\n",
    "6. Classifier-Free Diffusion Guidance - Ho, Salimans (2022)\n",
    "   https://arxiv.org/abs/2207.12598"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}